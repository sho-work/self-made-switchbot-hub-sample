import face_recognition
import cv2
import numpy as np
from switch_bot.find_by_uuid_and_press import run_bot_press
import time

def load_known_faces(image_paths):
    """æ—¢çŸ¥ã®é¡”ç”»åƒã‚’èª­ã¿è¾¼ã‚“ã§ç‰¹å¾´é‡ã‚’æŠ½å‡º"""
    known_face_encodings = []
    known_face_names = []

    for i, path in enumerate(image_paths):
        image = face_recognition.load_image_file(path)
        face_locations = face_recognition.face_locations(image, model="hog")

        if len(face_locations) == 1:
            encoding = face_recognition.face_encodings(image, face_locations)[0]
            known_face_encodings.append(encoding)
            known_face_names.append(f"Person_{i+1}")
            print(f"âœ… {path} ã®é¡”ãƒ‡ãƒ¼ã‚¿ã‚’ç™»éŒ²ã—ã¾ã—ãŸ")
        else:
            print(f"âš ï¸  {path} ã‹ã‚‰é¡”ã‚’æ¤œå‡ºã§ãã¾ã›ã‚“ã§ã—ãŸï¼ˆæ¤œå‡ºæ•°: {len(face_locations)}ï¼‰")

    return known_face_encodings, known_face_names

def run_camera_recognition(known_face_encodings, known_face_names, tolerance=0.4):
    """ã‚«ãƒ¡ãƒ©ã‚’ä½¿ç”¨ã—ãŸãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ é¡”èªè¨¼"""

    # ã‚«ãƒ¡ãƒ©ã‚’èµ·å‹•ï¼ˆ0ã¯é€šå¸¸å†…è”µã‚«ãƒ¡ãƒ©ï¼‰
    video_capture = cv2.VideoCapture(0)

    if not video_capture.isOpened():
        print("âŒ ã‚«ãƒ¡ãƒ©ã‚’é–‹ã‘ã¾ã›ã‚“ã§ã—ãŸ")
        return

    print("ğŸ“· ã‚«ãƒ¡ãƒ©ã‚’èµ·å‹•ã—ã¾ã—ãŸã€‚é¡”èªè¨¼ã‚’é–‹å§‹ã—ã¾ã™...")
    print("çµ‚äº†ã™ã‚‹ã«ã¯ 'q' ã‚­ãƒ¼ã‚’æŠ¼ã—ã¦ãã ã•ã„")

    # å‡¦ç†ã‚’è»½ãã™ã‚‹ãŸã‚ã€ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’ã‚¹ã‚­ãƒƒãƒ—
    process_this_frame = True
    last_recognition_time = 0
    recognition_cooldown = 5  # èªè¨¼æˆåŠŸå¾Œ5ç§’é–“ã¯å†èªè¨¼ã—ãªã„

    # å¤‰æ•°ã®åˆæœŸåŒ–
    face_locations = []
    face_names = []

    while True:
        # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—
        ret, frame = video_capture.read()

        if not ret:
            print("âš ï¸  ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ")
            break

        # å‡¦ç†ã‚’è»½ãã™ã‚‹ãŸã‚ã€2ãƒ•ãƒ¬ãƒ¼ãƒ ã«1å›ã ã‘å‡¦ç†
        if process_this_frame:
            # ç”»åƒã‚’1/4ã‚µã‚¤ã‚ºã«ãƒªã‚µã‚¤ã‚ºã—ã¦å‡¦ç†ã‚’é«˜é€ŸåŒ–
            small_frame = cv2.resize(frame, (0, 0), fx=0.25, fy=0.25)

            # BGRã‹ã‚‰RGBã«å¤‰æ›ï¼ˆOpenCVã¯BGRã€face_recognitionã¯RGBã‚’ä½¿ç”¨ï¼‰
            rgb_small_frame = cv2.cvtColor(small_frame, cv2.COLOR_BGR2RGB)

            # é¡”ã®ä½ç½®ã‚’æ¤œå‡º
            face_locations = face_recognition.face_locations(rgb_small_frame, model="hog")

            # æ¤œå‡ºã•ã‚ŒãŸé¡”ã®ç‰¹å¾´é‡ã‚’æŠ½å‡º
            face_encodings = face_recognition.face_encodings(rgb_small_frame, face_locations)

            face_names = []
            current_time = time.time()

            for face_encoding in face_encodings:
                # æ—¢çŸ¥ã®é¡”ã¨æ¯”è¼ƒ
                matches = face_recognition.compare_faces(known_face_encodings, face_encoding, tolerance=tolerance)
                name = "Unknown"

                # æœ€ã‚‚è¿‘ã„é¡”ã‚’è¦‹ã¤ã‘ã‚‹
                face_distances = face_recognition.face_distance(known_face_encodings, face_encoding)

                if len(face_distances) > 0:
                    best_match_index = np.argmin(face_distances)
                    if matches[best_match_index] and face_distances[best_match_index] < tolerance:
                        name = known_face_names[best_match_index]

                        # èªè¨¼æˆåŠŸæ™‚ã®å‡¦ç†ï¼ˆã‚¯ãƒ¼ãƒ«ãƒ€ã‚¦ãƒ³è€ƒæ…®ï¼‰
                        if current_time - last_recognition_time > recognition_cooldown:
                            print(f"ğŸ‰ é¡”èªè¨¼æˆåŠŸ: {name} (è·é›¢: {face_distances[best_match_index]:.3f})")

                            # SwitchBotã‚’å‹•ä½œã•ã›ã‚‹
                            try:
                                run_bot_press()
                                last_recognition_time = current_time
                            except Exception as e:
                                print(f"âš ï¸  SwitchBotåˆ¶å¾¡ã‚¨ãƒ©ãƒ¼: {e}")

                face_names.append(name)

        process_this_frame = not process_this_frame

        # çµæœã‚’ç”»é¢ã«è¡¨ç¤º
        for (top, right, bottom, left), name in zip(face_locations, face_names):
            # åº§æ¨™ã‚’å…ƒã®ã‚µã‚¤ã‚ºã«æˆ»ã™
            top *= 4
            right *= 4
            bottom *= 4
            left *= 4

            # é¡”ã®å‘¨ã‚Šã«æ ã‚’æç”»
            if name != "Unknown":
                color = (0, 255, 0)  # ç·‘ï¼šèªè¨¼æˆåŠŸ
            else:
                color = (0, 0, 255)  # èµ¤ï¼šæœªèªè¨¼

            cv2.rectangle(frame, (left, top), (right, bottom), color, 2)

            # åå‰ã‚’è¡¨ç¤º
            cv2.rectangle(frame, (left, bottom - 35), (right, bottom), color, cv2.FILLED)
            font = cv2.FONT_HERSHEY_DUPLEX
            cv2.putText(frame, name, (left + 6, bottom - 6), font, 0.6, (255, 255, 255), 1)

        # ãƒ•ãƒ¬ãƒ¼ãƒ ã‚’è¡¨ç¤º
        cv2.imshow('Face Recognition', frame)

        # 'q'ã‚­ãƒ¼ã§çµ‚äº†
        if cv2.waitKey(1) & 0xFF == ord('q'):
            print("ğŸ‘‹ ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‚’çµ‚äº†ã—ã¾ã™")
            break

    # å¾Œå‡¦ç†
    video_capture.release()
    cv2.destroyAllWindows()

def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    # ç™»éŒ²ã™ã‚‹é¡”ç”»åƒã®ãƒ‘ã‚¹
    known_face_paths = ["trainings/1.jpg", "trainings/2.jpg"]  # å¿…è¦ã«å¿œã˜ã¦è¤‡æ•°ã®ç”»åƒã‚’è¿½åŠ å¯èƒ½

    print("ğŸš€ é¡”èªè¨¼ã‚·ã‚¹ãƒ†ãƒ ã‚’èµ·å‹•ã—ã¾ã™...")

    # æ—¢çŸ¥ã®é¡”ã‚’èª­ã¿è¾¼ã¿
    known_face_encodings, known_face_names = load_known_faces(known_face_paths)

    if len(known_face_encodings) == 0:
        print("âŒ ç™»éŒ²ã•ã‚ŒãŸé¡”ãŒã‚ã‚Šã¾ã›ã‚“ã€‚train.jpg ã‚’ç¢ºèªã—ã¦ãã ã•ã„ã€‚")
        return

    print(f"âœ… {len(known_face_encodings)} ä»¶ã®é¡”ãƒ‡ãƒ¼ã‚¿ã‚’ç™»éŒ²ã—ã¾ã—ãŸ")

    # ã‚«ãƒ¡ãƒ©èªè¨¼ã‚’é–‹å§‹
    run_camera_recognition(known_face_encodings, known_face_names, tolerance=0.4)

if __name__ == "__main__":
    main()
